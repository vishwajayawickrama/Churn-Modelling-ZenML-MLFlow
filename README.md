# Enhanced MLflow Artifact Tracking for ML Pipelines

This project demonstrates production-ready machine learning pipelines with comprehensive MLflow artifact tracking, focusing on customer churn prediction.

## ğŸ¯ Project Overview

A complete ML system with enhanced MLflow tracking that provides:
- **Comprehensive Data Lineage**: Track data from raw input to final model predictions
- **Rich Artifact Management**: Automated logging of datasets, models, visualizations, and metadata
- **Production-Ready Monitoring**: Real-time inference tracking and performance monitoring
- **Complete Reproducibility**: All artifacts needed to reproduce experiments and results

## ğŸ“ Project Structure

```
Week 05_06/
â”œâ”€â”€ README.md                          # This file - comprehensive project documentation
â”œâ”€â”€ Makefile                           # Build and deployment automation
â”œâ”€â”€ config.yaml                        # Central configuration management
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ stepplan.md                       # Task planning and dependency tracking
â”‚
â”œâ”€â”€ artifacts/                         # Generated artifacts and models
â”‚   â”œâ”€â”€ data/                         # Processed datasets
â”‚   â”‚   â”œâ”€â”€ X_train.csv               # Training features
â”‚   â”‚   â”œâ”€â”€ X_test.csv                # Testing features
â”‚   â”‚   â”œâ”€â”€ Y_train.csv               # Training labels
â”‚   â”‚   â””â”€â”€ Y_test.csv                # Testing labels
â”‚   â”œâ”€â”€ encode/                       # Feature encoders
â”‚   â”‚   â”œâ”€â”€ Gender_encoder.json       # Gender feature encoder
â”‚   â”‚   â””â”€â”€ Geography_encoder.json    # Geography feature encoder
â”‚   â”œâ”€â”€ models/                       # Trained models
â”‚   â”‚   â””â”€â”€ churn_analysis.joblib     # Main trained model
â”‚   â””â”€â”€ mlflow_run_artifacts/         # MLflow-specific artifacts
â”‚       â””â”€â”€ {run_id}/                 # Run-specific artifacts
â”‚           â”œâ”€â”€ visualizations_*/     # Data visualizations by stage
â”‚           â””â”€â”€ final_csv_files/      # Final dataset metadata
â”‚
â”œâ”€â”€ data/                             # Data storage
â”‚   â”œâ”€â”€ raw/                          # Original raw data
â”‚   â”‚   â””â”€â”€ ChurnModelling.csv        # Raw customer churn dataset
â”‚   â””â”€â”€ processed/                    # Intermediate processed data
â”‚       â””â”€â”€ imputed.csv               # Data after missing value handling
â”‚
â”œâ”€â”€ mlruns/                           # MLflow tracking storage
â”‚   â”œâ”€â”€ 0/                           # Default experiment
â”‚   â”œâ”€â”€ models/                      # MLflow model registry
â”‚   â””â”€â”€ {experiment_id}/             # Experiment-specific runs
â”‚       â””â”€â”€ {run_id}/                # Individual run artifacts
â”‚           â”œâ”€â”€ artifacts/           # Run artifacts
â”‚           â”œâ”€â”€ metrics/             # Logged metrics
â”‚           â”œâ”€â”€ params/              # Logged parameters
â”‚           â””â”€â”€ tags/                # Run tags and metadata
â”‚
â”œâ”€â”€ pipelines/                        # ML pipeline implementations
â”‚   â”œâ”€â”€ __pycache__/                 # Python cache files
â”‚   â”œâ”€â”€ data_pipeline.py             # âœ¨ Enhanced data processing pipeline
â”‚   â”œâ”€â”€ training_pipeline.py         # âœ¨ Enhanced model training pipeline
â”‚   â””â”€â”€ streaming_inference_pipeline.py # âœ¨ Enhanced inference pipeline
â”‚
â”œâ”€â”€ src/                             # Core ML modules
â”‚   â”œâ”€â”€ __pycache__/                 # Python cache files
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”œâ”€â”€ data_ingestion.py            # Data loading and validation
â”‚   â”œâ”€â”€ data_spiltter.py             # Train/test splitting strategies
â”‚   â”œâ”€â”€ feature_binning.py           # Feature binning transformations
â”‚   â”œâ”€â”€ feature_encoding.py          # Feature encoding strategies
â”‚   â”œâ”€â”€ feature_scaling.py           # Feature scaling transformations
â”‚   â”œâ”€â”€ handle_missing_values.py     # Missing value handling strategies
â”‚   â”œâ”€â”€ model_building.py            # Model architecture definitions
â”‚   â”œâ”€â”€ model_evaluation.py          # Model evaluation metrics
â”‚   â”œâ”€â”€ model_inference.py           # Model inference and prediction
â”‚   â”œâ”€â”€ model_training.py            # Model training orchestration
â”‚   â””â”€â”€ outlier_detection.py         # Outlier detection and handling
â”‚
â””â”€â”€ utils/                           # Utility modules
    â”œâ”€â”€ __pycache__/                 # Python cache files
    â”œâ”€â”€ config.py                    # Configuration management
    â””â”€â”€ mlflow_utils.py              # MLflow tracking utilities
```

## ğŸš€ Key Enhancements Implemented

### 1. **Enhanced Data Pipeline** (`pipelines/data_pipeline.py`)

#### **ğŸ“Š Comprehensive Data Profiling**
- **Stage-wise Tracking**: Profiles data at each processing stage (raw â†’ missing_handled â†’ outliers_removed â†’ encoded â†’ final)
- **Rich Visualizations**: Automatic generation of distribution plots, correlation matrices
- **Dataset Artifacts**: Proper MLflow dataset tracking with lineage and versioning

#### **ğŸ” Data Quality Monitoring**
- **Metrics Tracking**: Rows, columns, missing values, memory usage at each stage
- **Transformation Logging**: Before/after metrics for each transformation step
- **Error Handling**: Graceful handling of processing failures with detailed logging

#### **ğŸ“ Artifact Management**
```python
# Example: Data profiling and visualization
create_data_visualizations(df, 'raw', run_artifacts_dir)
log_stage_metrics(df, 'raw')

# MLflow dataset tracking
raw_dataset = mlflow.data.from_pandas(df, source=data_path, name="raw_churn_data")
mlflow.log_input(raw_dataset, context="raw_data")
```

### 2. **Enhanced Training Pipeline** (`pipelines/training_pipeline.py`)

#### **ğŸ¯ Model Performance Tracking**
- **Comprehensive Visualizations**: Confusion matrices, ROC curves, feature importance plots
- **Training Metadata**: Training time, model size, complexity metrics
- **Performance Analytics**: Detailed model performance analysis and comparison

#### **ğŸ“ˆ Model Artifacts**
```python
# Example: Model performance visualization
create_model_performance_visualizations(model, X_test, y_test, evaluation_results, 
                                      run_artifacts_dir, 'XGboost')

# Model metadata logging
log_model_metadata(model, 'XGboost', model_params, training_time, run_artifacts_dir)
```

### 3. **Enhanced Inference Pipeline** (`pipelines/streaming_inference_pipeline.py`)

#### **âš¡ Real-time Monitoring**
- **Batch Processing**: Configurable batch sizes for efficient logging (default: 100 predictions)
- **Performance Tracking**: Inference time, prediction distributions, risk categorization
- **Production Monitoring**: Real-time model performance metrics

#### **ğŸ“Š Prediction Analytics**
```python
# Example: Inference tracking
class InferenceTracker:
    def track_prediction(self, input_data, prediction_result, inference_time):
        # Tracks individual predictions with metadata
        # Logs batches automatically when batch size is reached
```

## ğŸ› ï¸ MLflow Artifacts Generated

### **Data Pipeline Artifacts**
```
MLflow Run Artifacts:
â”œâ”€â”€ raw_data/                         # Original dataset
â”œâ”€â”€ visualizations/                   # Stage-wise data visualizations
â”‚   â”œâ”€â”€ raw/                         # Raw data distributions
â”‚   â”œâ”€â”€ encoded/                     # Post-encoding visualizations  
â”‚   â””â”€â”€ final/                       # Final processed data plots
â”œâ”€â”€ final_datasets/                   # Train/test CSV files with metadata
â”‚   â”œâ”€â”€ X_train.csv, X_test.csv      # Feature datasets
â”‚   â”œâ”€â”€ Y_train.csv, Y_test.csv      # Label datasets
â”‚   â””â”€â”€ final_csv_metadata.json      # Comprehensive metadata
â””â”€â”€ processed_datasets/               # Final processed datasets
```

### **Training Pipeline Artifacts**
```
MLflow Run Artifacts:
â”œâ”€â”€ model_performance/                # Model performance analysis
â”‚   â”œâ”€â”€ XGboost/                     # Model-specific artifacts
â”‚   â”‚   â”œâ”€â”€ confusion_matrix_XGboost.png
â”‚   â”‚   â”œâ”€â”€ roc_curve_XGboost.png
â”‚   â”‚   â”œâ”€â”€ feature_importance_XGboost.png
â”‚   â”‚   â””â”€â”€ prediction_distribution_XGboost.png
â”œâ”€â”€ model_metadata/                   # Model metadata and information
â”‚   â””â”€â”€ model_metadata_XGboost.json
â”œâ”€â”€ trained_models/                   # Actual model files
â”‚   â””â”€â”€ churn_analysis.joblib
â””â”€â”€ training_summary/                 # Complete training summary
    â””â”€â”€ training_summary.json
```

### **Inference Pipeline Artifacts**
```
MLflow Run Artifacts:
â”œâ”€â”€ inference_batches/                # Prediction batch logs
â”‚   â”œâ”€â”€ inference_batch_20241219_143022.json
â”‚   â””â”€â”€ inference_batch_20241219_143122.json
â””â”€â”€ prediction_analytics/             # Inference performance metrics
```

## ğŸ“Š MLflow Tracking Features

### **Dataset Tracking**
- **MLflow Datasets**: Proper dataset versioning and lineage tracking
- **Schema Evolution**: Automatic tracking of schema changes
- **Data Lineage**: Complete traceability from raw data to final models

### **Metrics Logged**
```python
# Data Pipeline Metrics
- raw_rows, raw_columns, raw_missing_values, raw_memory_mb
- missing_handled_rows_removed, outliers_removed_count
- final_train_samples, final_test_samples, final_features
- train_class_0, train_class_1, test_class_0, test_class_1

# Training Pipeline Metrics  
- training_time_seconds, model_size_mb, model_complexity
- accuracy, precision, recall, f1, roc_auc
- XGboost_training_time_seconds, XGboost_model_size_mb

# Inference Pipeline Metrics
- batch_size, avg_inference_time_ms, avg_churn_probability
- high_risk_predictions, medium_risk_predictions, low_risk_predictions
```

### **Parameters Logged**
```python
# Pipeline Configuration
- final_feature_names, preprocessing_steps, data_pipeline_version
- model_type, training_strategy, sklearn_version
- feature_encoding_applied, feature_scaling_applied

# Model Parameters
- n_estimators, max_depth, random_state
- test_size, missing_value_strategy, outlier_detection_method
```

## ğŸš€ Getting Started

### **Prerequisites**
```bash
# Install dependencies
pip install -r requirements.txt

# Or using uv (recommended)
uv pip install -r requirements.txt
```

### **Running the Pipelines**

#### **1. Data Pipeline**
```bash
# Run data processing pipeline
python pipelines/data_pipeline.py

# Or using Makefile
make data-pipeline
```

#### **2. Training Pipeline**
```bash
# Run model training pipeline
python pipelines/training_pipeline.py

# Or using Makefile  
make train-model
```

#### **3. Inference Pipeline**
```bash
# Run streaming inference
python pipelines/streaming_inference_pipeline.py

# Or using Makefile
make inference
```

### **MLflow UI**
```bash
# Start MLflow UI to view experiments and artifacts
mlflow ui

# Access at: http://localhost:5000
```

## ğŸ“ˆ Key Benefits

### **ğŸ” Enhanced Observability**
- **Complete Lineage**: Track data and model lineage from raw input to predictions
- **Rich Visualizations**: Automatic generation of insightful plots and charts
- **Comprehensive Metrics**: Detailed metrics at every pipeline stage

### **ğŸš€ Production Ready**
- **Error Handling**: Robust error handling with graceful degradation
- **Monitoring**: Real-time inference monitoring and performance tracking  
- **Reproducibility**: Complete artifact tracking for experiment reproduction

### **âš¡ Developer Experience**
- **Automated Tracking**: Minimal code changes for maximum tracking benefit
- **Rich Metadata**: Comprehensive metadata for all artifacts
- **Easy Debugging**: Quick access to intermediate results and visualizations

## ğŸ”§ Configuration

The system is configured through `config.yaml`:

```yaml
mlflow:
  tracking_uri: "file:./mlruns"
  experiment_name: "Zuu Crew Churn Analysis"  
  model_registry_name: "churn_prediction"
  artifact_path: "model"
  run_name_prefix: "churn_run"
  tags:
    project: "customer_churn_prediction"
    team: "ml_engineering" 
    environment: "development"
  autolog: true
```

## ğŸ“Š Performance Optimizations

### **Code Efficiency**
- **68% Code Reduction**: Optimized from ~950 lines to ~300 lines in data pipeline
- **Consolidated Functions**: Streamlined helper functions for better maintainability
- **Essential Visualizations**: Focus on most valuable plots and metrics

### **Resource Management**
- **Memory Efficient**: Efficient handling of large datasets with cleanup
- **Batch Processing**: Configurable batch sizes for inference tracking
- **Error Recovery**: Graceful fallbacks when artifact logging fails

## ğŸ¯ Future Enhancements

- **Data Drift Detection**: Monitor for data drift in production
- **Model Registry Management**: Automated model stage transitions  
- **Advanced Monitoring**: Additional performance and quality metrics
- **Integration Testing**: Comprehensive pipeline testing framework

## ğŸ“ Development Notes

This enhanced MLflow tracking system provides:
- **Production-grade logging** throughout all modules
- **Comprehensive error handling** and input validation  
- **Enhanced type safety** and documentation
- **Complete artifact traceability** for ML operations

The implementation follows clean architecture principles with separation of concerns and comprehensive observability for production ML systems.

---

**Built with â¤ï¸ for production-ready machine learning systems**
